defaults:
  - _self_
  - paths
  - dataset: coco

experiment:
  name: clipdiy_${dataset.name}
  run: final
  port: "12340"
  batch_size: 2
  num_workers: 8

output_dir: ${paths.results}

align_corners: False
saliency: True
model_name: clipconv
img_size: [256, 256]
patch_sizes: [256, 128, 64]
patch_w1: 1.0
patch_w2: 1.0
patch_w3: 1.0
strides: [2]
interpolate_logits: True
clip_model: laion/CLIP-ViT-B-32-laion2B-s34B-b79K
